{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric Benchmarking of Floquet Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import Optional, List\n",
    "import math\n",
    "import sinter\n",
    "import matplotlib\n",
    "import rsmf\n",
    "from main.codes.tic_tac_toe.gauge.GaugeFloquetColourCode import GaugeFloquetColourCode\n",
    "from main.codes.tic_tac_toe.gauge.GaugeHoneycombCode import GaugeHoneycombCode\n",
    "formatter : plt.Figure = rsmf.setup(r\"\\documentclass[a4paper,11pt,noarxiv]{quantumarticle}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinter_fit(log_ps, sqrt_qs, target_x, stat):\n",
    "    if len(log_ps) < 2:\n",
    "        print('error, less than 2 points')\n",
    "        return None\n",
    "    \n",
    "    slope_fit = sinter.fit_line_slope(\n",
    "        xs=log_ps,\n",
    "        ys=sqrt_qs,\n",
    "        max_extra_squared_error=1,\n",
    "    )\n",
    "    if slope_fit.best >= 0:\n",
    "        return None\n",
    "    \n",
    "    if slope_fit.high >= 0:\n",
    "        # Slope is going the wrong way! Definitely over threshold.\n",
    "        print('error, slope is going the wrong way')\n",
    "        return None\n",
    "\n",
    "    fit = sinter.fit_line_y_at_x(\n",
    "        xs=log_ps,\n",
    "        ys=sqrt_qs,\n",
    "        target_x=target_x,\n",
    "        max_extra_squared_error=1,  \n",
    "    )\n",
    "    return (fit)\n",
    "\n",
    "\n",
    "def extrapolate_footprint_achieving_error_rate(\n",
    "        group: List[sinter.TaskStats],\n",
    "        target_p: float,\n",
    ") -> Optional[sinter.Fit]:\n",
    "    \"\"\"Taken from Craig Gidney's code.\n",
    "    \n",
    "    Args:\n",
    "        group: A list of TaskStats objects.\n",
    "        target_p: The target probability of failure, for teraquop use 1e-12.\n",
    "\n",
    "    Returns:\n",
    "        A Fit object representing the footprint that would achieve the target\n",
    "        probability of failure, or None if the data was insufficient.\n",
    "    \"\"\"\n",
    "    assert len({stat.json_metadata['per'] for stat in group}) == 1\n",
    "    sqrt_qs = []\n",
    "    log_ps = []\n",
    "    for stat in group:\n",
    "        if stat.shots:\n",
    "            p_shot = stat.errors / stat.shots\n",
    "            if 0 < p_shot < 0.5:\n",
    "\n",
    "                p_unit = p_shot\n",
    "                sqrt_qs.append(math.sqrt(stat.json_metadata['distance']**2)) # huh why am is squaring and then taking the square root?\n",
    "                log_ps.append(math.log(p_unit))\n",
    "            \n",
    "\n",
    "    return get_sinter_fit(log_ps, sqrt_qs, math.log(target_p), stat)\n",
    "\n",
    "def low_error_for_multiplication(values, max_values):\n",
    "    relative_error = 0\n",
    "    abs_value = 1\n",
    "    for value, max_value in zip(values, max_values):\n",
    "        relative_error += (abs(max_value-value)/value)**2\n",
    "        abs_value *= value\n",
    "    \n",
    "    relative_error = math.sqrt(relative_error)\n",
    "    return(abs_value*(1-relative_error))\n",
    "\n",
    "def high_error_for_multiplication(values, max_values):\n",
    "    relative_error = 0\n",
    "    abs_value = 1\n",
    "    for value, max_value in zip(values, max_values):\n",
    "        relative_error += (abs(max_value-value)/value)**2\n",
    "        abs_value *= value\n",
    "\n",
    "    relative_error = math.sqrt(relative_error)\n",
    "\n",
    "    return(abs_value*(1+relative_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used to generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def float_to_color_shade(value: int, color_map: matplotlib.colors.LinearSegmentedColormap, vmin=200, vmax=3000):\n",
    "    \"\"\"\n",
    "    Convert a float between 1 and 1000 to a shade of blue.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : float\n",
    "        The float value to convert.\n",
    "    vmin : float\n",
    "        The minimum value of the range. Default is 1.\n",
    "    vmax : float\n",
    "        The maximum value of the range. Default is 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    color : tuple\n",
    "        The RGBA color corresponding to the input value.\n",
    "    \"\"\"\n",
    "    # Normalize the value to the range [0, 1]\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    normalized_value = norm(value)\n",
    "\n",
    "    # Get the color corresponding to the normalized value\n",
    "    color : Tuple[int,int,int,int]= color_map(normalized_value)\n",
    "    return color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats_memory : List[sinter.TaskStats] = sinter.stats_from_csv_files('./out/d_d_d_memory_experiment_0.001.csv')\n",
    "stats_stability : List[sinter.TaskStats] = sinter.stats_from_csv_files('./out/new_d_d_d_stability_experiment_0.001.csv')\n",
    "def filter_stats(stats, metadeta_entries: dict() = None, decoder = None):\n",
    "    for metadeta_key, metadeta_value in metadeta_entries.items():\n",
    "        stats = [stat for stat in stats if stat.json_metadata[metadeta_key] == metadeta_value]\n",
    "    if decoder:\n",
    "        stats = [stat for stat in stats if stat.decoder == decoder]\n",
    "    return stats\n",
    "\n",
    "stats_0001_memory_x_pymatching = filter_stats(stats_memory, metadeta_entries = {'per': 0.001, 'logical_observable': 'memory_x'}, decoder = 'pymatching')\n",
    "stats_0001_memory_z_pymatching = filter_stats(stats_memory, metadeta_entries = {'per': 0.001, 'logical_observable': 'memory_z'}, decoder = 'pymatching')\n",
    "stats_0001_memory_xz_pymatching = stats_0001_memory_x_pymatching + stats_0001_memory_z_pymatching\n",
    "\n",
    "stats_0001_memory_x_beliefmatching = filter_stats(stats_memory, metadeta_entries = {'per': 0.001, 'logical_observable': 'memory_x'}, decoder = 'beliefmatching')\n",
    "stats_0001_memory_z_beliefmatching = filter_stats(stats_memory, metadeta_entries = {'per': 0.001, 'logical_observable': 'memory_z'}, decoder = 'beliefmatching')\n",
    "stats_0001_memory_xz_beliefmatching = stats_0001_memory_x_beliefmatching + stats_0001_memory_z_beliefmatching\n",
    "\n",
    "stats_0001_stability_x_pymatching = filter_stats(stats_stability, metadeta_entries = {'per': 0.001, 'logical_observable': 'stability_x'}, decoder = 'pymatching')\n",
    "stats_0001_stability_z_pymatching = filter_stats(stats_stability, metadeta_entries = {'per': 0.001, 'logical_observable': 'stability_z'}, decoder = 'pymatching')\n",
    "stats_0001_stability_xz_pymatching = stats_0001_stability_x_pymatching + stats_0001_stability_z_pymatching\n",
    "\n",
    "stats_0001_stability_x_beliefmatching = filter_stats(stats_stability, metadeta_entries = {'per': 0.001, 'logical_observable': 'stability_x'}, decoder = 'beliefmatching')\n",
    "stats_0001_stability_z_beliefmatching = filter_stats(stats_stability, metadeta_entries = {'per': 0.001, 'logical_observable': 'stability_z'}, decoder = 'beliefmatching')\n",
    "stats_0001_stability_xz_beliefmatching = stats_0001_stability_x_beliefmatching + stats_0001_stability_z_beliefmatching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate x-side and z-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_teraquop_patch_diameter(stats):\n",
    "    noise_model_groups = sinter.group_by(stats, key = lambda stat: str(stat.json_metadata['px'])+ ',' + str(stat.json_metadata['py']) + ',' + str(stat.json_metadata['pz']) + ',' + str(stat.json_metadata['pm']))\n",
    "    noise_model_footprints = defaultdict()\n",
    "\n",
    "    for noise_model_key, noise_model_group in noise_model_groups.items():\n",
    "\n",
    "        code_name_groups = sinter.group_by(noise_model_group, key = lambda stat: (stat.json_metadata['code_name'], stat.json_metadata['gf_0'], stat.json_metadata['gf_1'], stat.json_metadata['gf_2']))\n",
    "        noise_model_footprints[noise_model_key] = defaultdict()\n",
    "        for code_name_key, code_name_group in code_name_groups.items(): \n",
    "            noise_model_footprints[noise_model_key][code_name_key] = extrapolate_footprint_achieving_error_rate(\n",
    "                    code_name_group,\n",
    "                    target_p=10**(-12))\n",
    "    return(noise_model_footprints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_patch_diameters = dict()\n",
    "z_patch_diameters = dict()\n",
    "x_patch_diameters[\"pymatching\"] = calc_teraquop_patch_diameter(stats_0001_memory_x_pymatching)\n",
    "z_patch_diameters[\"pymatching\"] = calc_teraquop_patch_diameter(stats_0001_memory_z_pymatching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_patch_diameters[\"beliefmatching\"] = calc_teraquop_patch_diameter(stats_0001_memory_x_beliefmatching)\n",
    "z_patch_diameters[\"beliefmatching\"] = calc_teraquop_patch_diameter(stats_0001_memory_z_beliefmatching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate number of qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_number_of_qubits(x_patch_diameters, z_patch_diamters):\n",
    "    number_of_qubits = dict()\n",
    "    for noise_model, diameters in x_patch_diameters.items():\n",
    "        number_of_qubits[noise_model] = dict()\n",
    "        for code_name, diameter in diameters.items():\n",
    "            if z_patch_diamters[noise_model][code_name] and diameter:\n",
    "\n",
    "                low_fit = 3*low_error_for_multiplication([diameter.best, z_patch_diamters[noise_model][code_name].best], [diameter.low, z_patch_diamters[noise_model][code_name].low])\n",
    "                high_fit = 3*high_error_for_multiplication([diameter.best, z_patch_diamters[noise_model][code_name].best], [diameter.high, z_patch_diamters[noise_model][code_name].high])\n",
    "                number_of_qubits[noise_model][code_name] = sinter.Fit(low=low_fit,\n",
    "                                                                    best=3 * diameter.best * z_patch_diamters[noise_model][code_name].best,\n",
    "                                                                        high=high_fit)\n",
    "            else:\n",
    "                print('error, no diameter', code_name, noise_model)\n",
    "    return(number_of_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_qubits = dict()\n",
    "number_of_qubits[\"pymatching\"] = calc_number_of_qubits(x_patch_diameters[\"pymatching\"], z_patch_diameters[\"pymatching\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, no diameter ('GaugeFloquetColourCode', 3, 3, 0) 1.0,1.0,4.0,1.0\n",
      "error, no diameter ('GaugeFloquetColourCode', 1, 3, 0) 1.0,1.0,8.0,1.0\n",
      "error, no diameter ('GaugeFloquetColourCode', 3, 3, 0) 1.0,1.0,8.0,4.0\n"
     ]
    }
   ],
   "source": [
    "number_of_qubits[\"beliefmatching\"] = calc_number_of_qubits(x_patch_diameters[\"beliefmatching\"], z_patch_diameters[\"beliefmatching\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate hight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_hight(distance_fit: sinter.Fit, code_string: str, letter):\n",
    "    if code_string[0] == \"GaugeFloquetColourCode\":\n",
    "        code = GaugeFloquetColourCode(4, [code_string[1], code_string[2]])\n",
    "    elif code_string[0] == \"GaugeHoneycombCode\":\n",
    "        code = GaugeHoneycombCode(4, [code_string[1], code_string[2], code_string[3]])\n",
    "    hight_low = code.get_graphlike_timelike_distance(math.ceil(distance_fit.low), letter, 'phenomenological_noise')\n",
    "    hight_best = code.get_graphlike_timelike_distance(math.ceil(distance_fit.best), letter, 'phenomenological_noise')\n",
    "    hight_high = code.get_graphlike_timelike_distance(math.ceil(distance_fit.high), letter, 'phenomenological_noise')\n",
    "    return(sinter.Fit(hight_low, hight_best, hight_high))\n",
    "\n",
    "\n",
    "def calc_hight(stats, letter):\n",
    "    noise_model_groups = sinter.group_by(stats, key = lambda stat: str(stat.json_metadata['px'])+ ',' + str(stat.json_metadata['py']) + ',' + str(stat.json_metadata['pz']) + ',' + str(stat.json_metadata['pm']))\n",
    "    noise_model_footprints = defaultdict()\n",
    "    noise_model_hights = defaultdict()\n",
    "\n",
    "    for noise_model_key, noise_model_group in noise_model_groups.items():\n",
    "\n",
    "        code_name_groups = sinter.group_by(noise_model_group, key = lambda stat: (stat.json_metadata['code_name'], stat.json_metadata['gf_0'], stat.json_metadata['gf_1'], stat.json_metadata['gf_2']))\n",
    "        noise_model_footprints[noise_model_key] = defaultdict()\n",
    "        noise_model_hights[noise_model_key] = defaultdict()\n",
    "        for code_name_key, code_name_group in code_name_groups.items(): \n",
    "            noise_model_footprints[noise_model_key][code_name_key] = extrapolate_footprint_achieving_error_rate(\n",
    "                    code_name_group,\n",
    "                    target_p=10**(-12))\n",
    "            if noise_model_footprints[noise_model_key][code_name_key] != None:\n",
    "                noise_model_hights[noise_model_key][code_name_key] = distance_to_hight(noise_model_footprints[noise_model_key][code_name_key], code_name_key, letter)\n",
    "    return(noise_model_hights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, slope is going the wrong way\n"
     ]
    }
   ],
   "source": [
    "x_hights_stability=dict()\n",
    "x_hights_stability[\"pymatching\"] = calc_hight(stats_0001_stability_x_pymatching, 'X')\n",
    "x_hights_stability[\"beliefmatching\"] = calc_hight(stats_0001_stability_x_beliefmatching, 'X')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, less than 2 points\n",
      "error, less than 2 points\n"
     ]
    }
   ],
   "source": [
    "z_hights_stability=dict()\n",
    "\n",
    "z_hights_stability[\"pymatching\"] = calc_hight(stats_0001_stability_z_pymatching, 'Z')\n",
    "z_hights_stability[\"beliefmatching\"] = calc_hight(stats_0001_stability_z_beliefmatching, 'Z')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_xz_hight(x_hights_stability, z_hights_stability):\n",
    "    xz_hight = dict()\n",
    "    for noise_model, x_hights_stability in x_hights_stability.items():\n",
    "        xz_hight[noise_model] = dict()\n",
    "        for code_name, x_hight in x_hights_stability.items():\n",
    "\n",
    "            if code_name in z_hights_stability[noise_model]:\n",
    "                z_hight = z_hights_stability[noise_model][code_name]\n",
    "                xz_hight[noise_model][code_name] = sinter.Fit((x_hight.low + z_hight.low)/2, (x_hight.best + z_hight.best)/2, (x_hight.high + z_hight.high)/2)\n",
    "            else:\n",
    "                z_hight = None\n",
    "                print('error, no hight', code_name, noise_model)\n",
    "           \n",
    "                \n",
    "\n",
    "    return(xz_hight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xz_hight = dict()\n",
    "xz_hight[\"pymatching\"] = calc_xz_hight(x_hights_stability[\"pymatching\"], z_hights_stability[\"pymatching\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, no hight ('GaugeFloquetColourCode', 1, 1, 0) 1.0,1.0,16.0,1.0\n",
      "error, no hight ('GaugeFloquetColourCode', 2, 1, 0) 1.0,1.0,16.0,1.0\n"
     ]
    }
   ],
   "source": [
    "xz_hight[\"beliefmatching\"] = calc_xz_hight(x_hights_stability[\"beliefmatching\"], z_hights_stability[\"beliefmatching\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_volumes(number_of_qubits, xz_hight):\n",
    "    volumes = dict()\n",
    "    for noise_model, code_name in number_of_qubits.items():\n",
    "        volumes[noise_model] = dict()\n",
    "        for code_name, number_of_qubit in code_name.items():\n",
    "            if code_name in xz_hight[noise_model] and xz_hight[noise_model][code_name] != None:\n",
    "                low_fit = low_error_for_multiplication([number_of_qubit.best, xz_hight[noise_model][code_name].best], [number_of_qubit.low, xz_hight[noise_model][code_name].low])\n",
    "                high_fit = high_error_for_multiplication([number_of_qubit.best, xz_hight[noise_model][code_name].best], [number_of_qubit.high, xz_hight[noise_model][code_name].high])\n",
    "                volumes[noise_model][code_name] = sinter.Fit(low=low_fit,\n",
    "                        best=number_of_qubit.best * xz_hight[noise_model][code_name].best,\n",
    "                        high=high_fit)\n",
    "\n",
    "    return(volumes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = dict()\n",
    "volumes[\"pymatching\"] = calc_volumes(number_of_qubits[\"pymatching\"], xz_hight[\"pymatching\"])\n",
    "volumes[\"beliefmatching\"] = calc_volumes(number_of_qubits[\"beliefmatching\"], xz_hight[\"beliefmatching\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_volume(volumes_at_noise_model):\n",
    "    best_volume_val = None\n",
    "    best_volume_name = None\n",
    "    for code_name, volumes in volumes_at_noise_model.items():\n",
    "        if volumes.best is not None and (best_volume_val is None or volumes.best < best_volume_val):\n",
    "            best_volume_val = volumes.best\n",
    "            best_volume_name = code_name\n",
    "    return best_volume_name, best_volume_val\n",
    "\n",
    "def get_best_volumes(volumes):\n",
    "    best_codes = dict()\n",
    "    for noise_model in volumes.keys():\n",
    "        best_codes[noise_model] = get_best_volume(volumes[noise_model])\n",
    "    return(best_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_codes = dict()\n",
    "best_codes['pymatching'] = get_best_volumes(volumes[\"pymatching\"])\n",
    "best_codes['beliefmatching'] = get_best_volumes(volumes[\"beliefmatching\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for generating plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_footprints(best_codes: dict, ax: plt.Axes, vmin, vmax):\n",
    "\n",
    "    x_y_to_color = dict()\n",
    "    x_values = list()\n",
    "    y_values = list()\n",
    "    for noise_model, best_code in best_codes.items():\n",
    "        x_val = float(noise_model.split(',')[-2])\n",
    "        y_val = float(noise_model.split(',')[-1])\n",
    "    \n",
    "        if best_code[0][0] == 'GaugeHoneycombCode':\n",
    "            x_y_to_color[(x_val, y_val)] = float_to_color_shade(best_code[1], plt.cm.Greens,vmin,vmax)\n",
    "        elif best_code[0][0] == 'GaugeFloquetColourCode':\n",
    "            x_y_to_color[(x_val, y_val)] = float_to_color_shade(best_code[1], plt.cm.Reds,vmin,vmax)    \n",
    "\n",
    "        if x_val not in x_values:\n",
    "            x_values.append(x_val)\n",
    "        if y_val not in y_values:\n",
    "            y_values.append(y_val)\n",
    "\n",
    "\n",
    "    x_values.sort()\n",
    "    y_values.sort()\n",
    "\n",
    "    color_matrix = [[0 for i in range(len(y_values))] for j in range(len(x_values))]\n",
    "    for x_val in x_values:\n",
    "        for y_val in y_values:\n",
    "            if (x_val, y_val) in x_y_to_color:\n",
    "                color_matrix[y_values.index(y_val)][x_values.index(x_val)] = x_y_to_color[(x_val, y_val)]\n",
    "\n",
    "    ax.imshow(color_matrix, origin = 'lower')\n",
    "    ax.set_xticks(np.arange(len(x_values)), labels=x_values)\n",
    "    ax.set_yticks(np.arange(len(y_values)), labels=y_values)\n",
    "    ax.set_xlabel('Z error bias')\n",
    "    ax.set_ylabel('Measurement error bias',)\n",
    "    \n",
    "def format_code_label(code_name):\n",
    "    code_name_to_label = {\n",
    "        'GaugeHoneycombCode': 'HCC',\n",
    "        'GaugeFloquetColourCode': 'FCC'\n",
    "    }\n",
    "    if code_name_to_label.get(code_name[0], code_name) == 'HCC':\n",
    "        return(f\"$X^{code_name[1:][0]}Y^{code_name[1:][1]}Z^{code_name[1:][2]}$\")\n",
    "    else:\n",
    "        return(f\"$X^{code_name[1:][0]}Z^{code_name[1:][1]}$\")\n",
    "\n",
    "\n",
    "\n",
    "def plot_footprints(footprints,error_model, ax=plt, top_n=10, vmin=10,vmax=80, y_label = 'Patch diameter'):\n",
    "\n",
    "    sorted_items = sorted(footprints[error_model].items(), key=lambda item: item[1].best if item[1] is not None else float('inf'))\n",
    "    code_name_to_color = {'GaugeFloquetColourCode': plt.cm.Reds, 'GaugeHoneycombCode': plt.cm.Greens}\n",
    "    for code_name, footprint in sorted_items[:top_n]:\n",
    "        formatted_label = format_code_label(code_name)            \n",
    "        bars = ax.bar(str(code_name), float(footprint.best), color = float_to_color_shade(footprint.best, code_name_to_color.get(code_name[0], 'black'), vmin=vmin, vmax=vmax))\n",
    "        ax.errorbar(str(code_name), float(footprint.best), yerr=[[float(footprint.best - footprint.low)], [float(footprint.high - footprint.best)],], fmt='o', color='black', ecolor='black', elinewidth=1, capsize=3)\n",
    "        for bar in bars:\n",
    "            height = 1.03*footprint.high\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2.0, height, formatted_label, ha='center', va='bottom', rotation=90)\n",
    "    ax.set_ylim(0, footprint.high + footprint.best)\n",
    "\n",
    "#    ax.set_xlabel('Codes')\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xticks([]) \n",
    " \n",
    "def draw_corner_bar_plots(footprints, fig, axd, n_points, vmin, vmax, ylabel, ymax):\n",
    "    plot_footprints(footprints, '1.0,1.0,1.0,16.0', axd['A'],n_points, vmin=vmin, vmax=vmax, y_label=ylabel) \n",
    "    plot_footprints(footprints, '1.0,1.0,16.0,16.0', axd['C'],n_points, vmin=vmin, vmax=vmax, y_label=ylabel)\n",
    "\n",
    "    plot_footprints(footprints, '1.0,1.0,1.0,1.0', axd['D'],n_points, vmin=vmin, vmax=vmax, y_label=ylabel) \n",
    "    plot_footprints(footprints, '1.0,1.0,16.0,1.0', axd['E'], n_points, vmin=vmin, vmax=vmax, y_label=ylabel)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    axd['A'].set_ylim(0, ymax)\n",
    "    axd['C'].sharey(axd['A'])\n",
    "    axd['D'].sharey(axd['A'])\n",
    "    axd['E'].sharey(axd['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overview_plot(decoder: str,vmin: int, vmax: int, ymax: int):\n",
    "\n",
    "    layout = [['A',   'C'],\n",
    "            [ 'B',   'B',],\n",
    "            [ 'B', 'B'],\n",
    "            ['D', 'E']]\n",
    "    fig : plt.Figure = formatter.figure(width_ratio=2, aspect_ratio=1.5)\n",
    "    axd = fig.subplot_mosaic(layout, height_ratios=[1, 0.5, 0.5, 1],)\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    axd['A'].set_title('Volumes of the 10 best codes at \\n Measurement bias 16, \\n Z error bias 1')\n",
    "    axd['C'].set_title('Volumes of the 10 best codes at \\n Measurement bias 16, \\n Z error bias 16')\n",
    "    axd['D'].set_title('Volumes of the 10 best codes at \\n Measurement bias 1 \\n Z error bias 1')\n",
    "    axd['E'].set_title('Volumes of the 10 best codes at \\n Measurement bias 1 \\n Z error bias 16')\n",
    "    axd['B'].set_title('Volumes of the best code at each bias')\n",
    "\n",
    "    plot_best_footprints(best_codes[decoder], axd['B'], vmin, vmax)\n",
    "    draw_corner_bar_plots(volumes[decoder], fig, axd, 10, vmin, vmax, r\"qubits $\\times$ rounds\", ymax)\n",
    "\n",
    "\n",
    "    cb1=plt.colorbar(mappable=plt.cm.ScalarMappable(norm=mcolors.Normalize(vmin=vmin, vmax=vmax), cmap=plt.cm.Greens), ax=axd['B'], label='volume of $X^a Y^b Z^c$  DCCC')\n",
    "    cb2=plt.colorbar(mappable=plt.cm.ScalarMappable(norm=mcolors.Normalize(vmin=vmin, vmax=vmax), cmap=plt.cm.Reds), ax=axd['B'], label='volume of $X^a Z^b$ DCCC')\n",
    "    fig.tight_layout()\n",
    "    l, b, w, h = axd['B'].get_position().bounds\n",
    "    axd['B'].set_position([l, b+0.05, w, h])\n",
    "    l, b, w, h = cb1.ax.get_position().bounds\n",
    "    cb1.ax.set_position([l, b+0.05, w, h])\n",
    "    l, b, w, h = cb2.ax.get_position().bounds\n",
    "    cb2.ax.set_position([l, b+0.05, w, h])\n",
    "    fig.savefig(f'spacetime_volume_heatmap_{decoder}.pdf', bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_overview_plot('pymatching', 10e2, 10e4, 3e5)\n",
    "create_overview_plot('beliefmatching', 10e2, 10e4, 1.5e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hcc_fcc_footprints(footprints, error_model, decoder):\n",
    "    footprints_all_codes = [diameter for key,diameter in footprints[decoder].items() if key == error_model]\n",
    "    footprints_hcc_fcc = {key: diameter for key,diameter in footprints_all_codes[0].items() if (key == ('GaugeFloquetColourCode', 1, 1, 0) or key == ('GaugeHoneycombCode', 1, 1, 1))}\n",
    "    return footprints_hcc_fcc\n",
    "\n",
    "def plot_all_footprints_fcc_hcc(footprints_list, error_model, ax=plt, x_labels=[], vmin=10,vmax=80, y_label = 'Patch diameter'):\n",
    "    pos = 0\n",
    "    code_name_to_color = {'GaugeFloquetColourCode': 'Red', 'GaugeHoneycombCode': 'Green'}\n",
    "\n",
    "    for footprints in footprints_list:\n",
    "        footprints_hcc_fcc_pymatching = get_hcc_fcc_footprints(footprints, error_model, 'pymatching')\n",
    "        footprints_hcc_fcc_beliefmatching = get_hcc_fcc_footprints(footprints, error_model, 'beliefmatching')\n",
    "\n",
    "\n",
    "        for code_name, footprint in footprints_hcc_fcc_pymatching.items():\n",
    "            ax : plt.axes\n",
    "          \n",
    "            bars = ax.bar(pos, float(footprint.best), color=code_name_to_color.get(code_name[0], 'black'), hatch='x', edgecolor='black')\n",
    "            ax.errorbar(pos, float(footprint.best), yerr=[[float(footprint.best - footprint.low)], [float(footprint.high - footprint.best)],], fmt='o', color='black', ecolor='black', elinewidth=1, capsize=3)\n",
    "\n",
    "            pos += 1\n",
    "                 \n",
    "            bm_code_footprint = footprints_hcc_fcc_beliefmatching.get(code_name)\n",
    "\n",
    "            bars = ax.bar(pos, float(bm_code_footprint.best), color=code_name_to_color.get(code_name[0], 'black'), edgecolor='black')\n",
    "            ax.errorbar(pos, float(bm_code_footprint.best), yerr=[[float(bm_code_footprint.best - bm_code_footprint.low)], [float(bm_code_footprint.high - bm_code_footprint.best)],], fmt='o', color='black', ecolor='black', elinewidth=1, capsize=3)\n",
    "            pos += 1.2\n",
    "        pos += 1\n",
    "\n",
    "    formatter = matplotlib.ticker.ScalarFormatter(useMathText=True)\n",
    "    formatter.fontsize = 11\n",
    "    formatter.set_scientific(True)\n",
    "    formatter.set_powerlimits((-1, 1))\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xticks(x_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = formatter.figure(wide=True)\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# create 3x1 subfigs\n",
    "subfigs = fig.subfigures(nrows=3, ncols=1)\n",
    "#fig.tight_layout()\n",
    "\n",
    "# create 1x3 subplots per subfig\n",
    "axs = subfigs[0].subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios': [3, 1]})\n",
    "x_labels = ['$\\\\tilde{n}_E$', '$\\\\tilde{n}_M$', '$h_E$', '$h_M$']\n",
    "plot_all_footprints_fcc_hcc([x_patch_diameters, z_patch_diameters, x_hights_stability, z_hights_stability],'1.0,1.0,1.0,1.0', axs[0], y_label= '')\n",
    "plot_all_footprints_fcc_hcc([volumes], '1.0,1.0,1.0,1.0', axs[1], y_label= 'teraquop volume')\n",
    "subfigs[0].suptitle(f'Z error bias = 1, Measurement bias = 1')\n",
    "\n",
    "#print(\"\\n\")\n",
    "axs = subfigs[1].subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios': [3, 1]})\n",
    "subfigs[1].suptitle(f'Z error bias = 8, Measurement bias = 1')\n",
    "plot_all_footprints_fcc_hcc([x_patch_diameters, z_patch_diameters, x_hights_stability],'1.0,1.0,8.0,1.0', axs[0], y_label= '')\n",
    "plot_all_footprints_fcc_hcc([x_patch_diameters, z_patch_diameters, x_hights_stability, z_hights_stability],'1.0,1.0,8.0,1.0', axs[0], y_label= '')\n",
    "plot_all_footprints_fcc_hcc([volumes], '1.0,1.0,8.0,1.0', axs[1], y_label= 'teraquop volume')\n",
    "#axs[0].set_xticks([0.5,3.5,6.5,9.5], x_labels)\n",
    "\n",
    "subfigs[2].suptitle(f'Z error bias = 1, Measurement bias = 8')\n",
    "axs = subfigs[2].subplots(nrows=1, ncols=2, gridspec_kw={'width_ratios': [3, 1]})\n",
    "\n",
    "plot_all_footprints_fcc_hcc([x_patch_diameters, z_patch_diameters, x_hights_stability, z_hights_stability],'1.0,1.0,1.0,16.0', axs[0], y_label= '')\n",
    "plot_all_footprints_fcc_hcc([volumes], '1.0,1.0,1.0,16.0', axs[1], y_label= 'teraquop volume')\n",
    "axs[0].set_xticks([0.5,3.5,6.5,9.5], x_labels)\n",
    "red_patch_pm = mpatches.Patch(label='$X^1Z^1$ PyMatching', edgecolor='black', hatch='//', facecolor='red')\n",
    "red_patch_bm = mpatches.Patch(label='$X^1Z^1$ belief-matching', edgecolor='black', facecolor='red')\n",
    "green_patch_pm = mpatches.Patch(facecolor='green', label='$X^1Y^1Z^1$ PyMatching', edgecolor='black', hatch='//')\n",
    "green_patch_bm = mpatches.Patch(facecolor='green', label='$X^1Y^1Z^1$ belief-matching', edgecolor='black')\n",
    "axs[0].set_xticks([1.625,7,12.375,17.8], x_labels)\n",
    "axs[0].legend(handles=[red_patch_pm, red_patch_bm, green_patch_pm, green_patch_bm], loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "\n",
    "fig.savefig('CSS_DCCC_XYZ_DCCC_comparison.pdf', bbox_inches='tight')\n",
    "plt.close(fig)  # Close the figure to free up memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1.0,1.0,1.0,16.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvolumes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1.0,1.0,1.0,16.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGaugeFloquetColourCode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)]\u001b[38;5;241m.\u001b[39mbest\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10e-7\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(volumes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.0,1.0,1.0,16.0\u001b[39m\u001b[38;5;124m'\u001b[39m][(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGaugeFloquetColourCode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)]\u001b[38;5;241m.\u001b[39mbest\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10e-7\u001b[39m)\n\u001b[1;32m      4\u001b[0m sinter\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mKeyError\u001b[0m: '1.0,1.0,1.0,16.0'"
     ]
    }
   ],
   "source": [
    "print(volumes['1.0,1.0,1.0,16.0'][(\"GaugeFloquetColourCode\",2,2,0)].best*10e-7)\n",
    "print(volumes['1.0,1.0,1.0,16.0'][(\"GaugeFloquetColourCode\",1,1,0)].best*10e-7)\n",
    "\n",
    "sinter.collect()\n",
    "#print(volumes_SI1000[(\"GaugeHoneycombCode\",2,1,1)].best*10e-8)\n",
    "#rint(volumes_SI1000[(\"GaugeFloquetColourCode\",1,1,0)].best/volumes_SI1000[(\"GaugeHoneycombCode\",2,1,1)].best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "categories = ['A']\n",
    "values1 = [10]\n",
    "values2 = [6]\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.4\n",
    "\n",
    "# Positions of the bars on the x-axis\n",
    "r1 = np.arange(len(categories))\n",
    "r2 = [x - bar_width/2 for x in r1]\n",
    "plt.figure()\n",
    "# Create bars\n",
    "plt.bar(r1, values1, color='b', width=bar_width, edgecolor='grey', label='Bigger Bar')\n",
    "plt.bar(r2, values2, color='r', width=bar_width, edgecolor='grey', label='Smaller Bar')\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel('Category', fontweight='bold')\n",
    "plt.xticks([r for r in range(len(categories))], categories)\n",
    "plt.ylabel('Values', fontweight='bold')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.savefig('barplot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
